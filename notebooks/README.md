# ğŸ““ Notebooks - ANP Classifier

## ğŸ“‹ VisÃ£o Geral

Este diretÃ³rio contÃ©m Jupyter Notebooks para processamento de documentos normativos da ANP e geraÃ§Ã£o de artefatos para o classificador LATS-P.

---

## ğŸ“š Notebooks DisponÃ­veis

### 1. `ANP_pdf_to_KG_policy_tree.ipynb` â­ PRINCIPAL

**Objetivo**: Pipeline completo de extraÃ§Ã£o de PDFs normativos da ANP atÃ© geraÃ§Ã£o de Ã¡rvore de decisÃ£o JSON.

**Fluxo**:
```
PDFs Normativos
    â†“
[0] Setup e Imports
    â†“
[1] Descoberta de PDFs
    â†“
[2] ExtraÃ§Ã£o de Texto (PyMuPDF + OCR fallback)
    â†“
[3] Limpeza e NormalizaÃ§Ã£o
    â†“
[4] Chunking (por seÃ§Ãµes ou tamanho)
    â†“
[5] ConfiguraÃ§Ã£o LLM (Azure OpenAI)
    â†“
[6] Knowledge Graph (LLMGraphTransformer)
    â†“
[7] Policy Graph (projeÃ§Ã£o decisÃ³ria)
    â†“
[7.5] DetecÃ§Ã£o AutomÃ¡tica de Subpolicies âœ¨ NOVO
    â†“
[8] CompilaÃ§Ã£o em Ãrvore JSON (com branching por subpolicies)
    â†“
[9] RelatÃ³rio de Qualidade
    â†“
[10] Smoke Test
    â†“
Artefatos Finais (artifacts/)
```

**Outputs**:
- `artifacts/anp_text_corpus.jsonl` - Textos limpos
- `artifacts/anp_kg.graphml` - Knowledge Graph completo
- `artifacts/anp_kg.json` - Knowledge Graph (JSON)
- `artifacts/anp_policy.graphml` - Policy Graph (DAG)
- `artifacts/anp_policy.json` - Policy Graph (JSON)
- `artifacts/anp_tree.json` - Ãrvore de decisÃ£o final âœ¨

---

## ğŸš€ Como Usar

### PrÃ©-requisitos

1. **Python 3.10+** com Jupyter instalado
2. **Azure OpenAI** configurado (credenciais no `.env`)
3. **Tesseract OCR** instalado (opcional, para PDFs com imagens)

### InstalaÃ§Ã£o de DependÃªncias

```bash
# Criar ambiente virtual (recomendado)
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# ou
.venv\Scripts\activate     # Windows

# Instalar dependÃªncias
pip install pymupdf pdfplumber pytesseract pillow langchain langchain-experimental langchain-openai networkx pydantic python-dotenv tqdm matplotlib jupyter
```

### InstalaÃ§Ã£o do Tesseract (opcional)

**Ubuntu/Debian**:
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-por
```

**macOS**:
```bash
brew install tesseract tesseract-lang
```

**Windows**:
Download do instalador: https://github.com/UB-Mannheim/tesseract/wiki

### Preparar PDFs

Coloque os PDFs normativos da ANP em:
```
padroes_anp/
â”œâ”€â”€ portaria_anp_XXX.pdf
â”œâ”€â”€ resolucao_anp_YYY.pdf
â””â”€â”€ ...
```

### Configurar Azure OpenAI

Crie arquivo `.env` na raiz do projeto:

```bash
# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://seu-endpoint.openai.azure.com/
AZURE_OPENAI_API_KEY=sua-chave-api
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4o-mini
```

### Executar Notebook

```bash
# Iniciar Jupyter
jupyter notebook notebooks/ANP_pdf_to_KG_policy_tree.ipynb

# Ou usar JupyterLab
jupyter lab notebooks/ANP_pdf_to_KG_policy_tree.ipynb
```

### Modo de Teste vs ProduÃ§Ã£o

Por padrÃ£o, o notebook estÃ¡ em **MODO DE TESTE** (processa apenas 10 chunks):

```python
TEST_MODE = True  # Processar apenas 10 chunks
MAX_CHUNKS_TEST = 10
```

Para processar **corpus completo** (âš ï¸ pode custar muito em tokens):

```python
TEST_MODE = False  # Processar todos os chunks
```

---

## ğŸ“Š Estrutura dos Artefatos

### 1. `anp_text_corpus.jsonl`

Corpus de textos limpos, um documento por linha:

```json
{
  "doc_id": "a1b2c3d4e5f6",
  "filename": "portaria_anp_123.pdf",
  "text_clean": "Texto normalizado e limpo...",
  "num_chars": 45678,
  "num_words": 7890
}
```

### 2. `anp_kg.graphml` / `anp_kg.json`

Knowledge Graph completo com entidades normativas:

**Tipos de NÃ³s**:
- `IncidentType` - Tipos de incidente
- `Criterion` - CritÃ©rios decisÃ³rios
- `Threshold` - Limiares numÃ©ricos
- `Classification` - ClassificaÃ§Ãµes (Classe 1, 2, etc)
- `Obligation` - ObrigaÃ§Ãµes normativas
- `Exception` - ExceÃ§Ãµes
- `Actor` - Atores envolvidos
- `Evidence` - EvidÃªncias necessÃ¡rias

**Tipos de RelaÃ§Ãµes**:
- `DEPENDS_ON` - DependÃªncia entre critÃ©rios
- `CLASSIFIED_AS` - Leva Ã  classificaÃ§Ã£o
- `IMPLIES` - Implica consequÃªncia
- `REQUIRES` - Requer evidÃªncia/aÃ§Ã£o
- `HAS_THRESHOLD` - Possui limiar
- `HAS_EXCEPTION` - Possui exceÃ§Ã£o
- `APPLIES_TO` - Aplica-se a
- `EVIDENCED_BY` - Evidenciado por

### 3. `anp_policy.graphml` / `anp_policy.json`

Policy Graph (projeÃ§Ã£o decisÃ³ria do KG):

- Subgrafo do KG focado em decisÃ£o
- Apenas nÃ³s/arestas relevantes para classificaÃ§Ã£o
- Validado como DAG (sem ciclos)

### 4. `anp_tree.json` âœ¨ PRINCIPAL

Ãrvore de decisÃ£o final, compatÃ­vel com classificador LATS-P:

```json
{
  "id": "raiz",
  "pergunta": "Qual o tipo de ocorrÃªncia?",
  "tipo": "decisao",
  "subnodos": [
    {
      "id": "lesao_forca_trabalho",
      "pergunta": "Acidente com LesÃ£o na ForÃ§a de Trabalho",
      "tipo": "decisao",
      "subnodos": [
        {
          "id": "criterio_gravidade",
          "pergunta": "Qual a gravidade da lesÃ£o?",
          "tipo": "decisao",
          "subnodos": [
            {
              "id": "classe_1_terminal",
              "tipo": "terminal",
              "classe": "Classe 1"
            }
          ]
        }
      ]
    }
  ]
}
```

**Estrutura**:
- **NÃ³s de DecisÃ£o**: `tipo: "decisao"` com `pergunta` e `subnodos`
- **NÃ³s Terminais**: `tipo: "terminal"` com `classe`

---

## âœ¨ DetecÃ§Ã£o AutomÃ¡tica de Subpolicies (NOVO)

**SeÃ§Ã£o [7.5]**: Implementa detecÃ§Ã£o automÃ¡tica de comunidades (subpolicies) usando teoria de grafos.

### Fundamento TeÃ³rico

**DetecÃ§Ã£o de Comunidades**:
- Algoritmo: `greedy_modularity_communities` (NetworkX)
- PrincÃ­pio: OtimizaÃ§Ã£o de modularidade
- Resultado: Clusters naturais de nÃ³s = subpolicies (domÃ­nios normativos)

**IdentificaÃ§Ã£o de NÃ³s CrÃ­ticos**:
- MÃ©trica: Betweenness centrality
- Significado: NÃ³s que conectam diferentes partes do grafo (pontes estruturais)
- Uso: Auditoria de critÃ©rios decisÃ³rios mais importantes

### Vantagens

âœ… **EliminaÃ§Ã£o de heurÃ­sticas manuais** - Baseado exclusivamente na topologia do grafo
âœ… **ReduÃ§Ã£o de entropia** - Branching inicial por domÃ­nio normativo
âœ… **Maior granularidade** - Aumento de nÃ³s terminais
âœ… **DeterminÃ­stico** - Mesmos inputs â†’ mesmos outputs
âœ… **AuditÃ¡vel** - Cada decisÃ£o tem fundamentaÃ§Ã£o estrutural

### Estrutura da Ãrvore com Subpolicies

```json
{
  "id": "raiz",
  "pergunta": "Qual o tipo de ocorrÃªncia?",
  "tipo": "decisao",
  "subnodos": [
    {
      "id": "subpolicy_0",
      "pergunta": "Acidente com LesÃ£o na ForÃ§a de Trabalho",
      "tipo": "decisao",
      "subnodos": [ /* critÃ©rios especÃ­ficos */ ]
    },
    {
      "id": "subpolicy_1",
      "pergunta": "Acidente com Impacto no Meio Ambiente",
      "tipo": "decisao",
      "subnodos": [ /* critÃ©rios especÃ­ficos */ ]
    }
  ]
}
```

**Resultado**: Ãrvore hierÃ¡rquica com ramificaÃ§Ã£o semÃ¢ntica, reduzindo entropia e melhorando navegaÃ§Ã£o LATS-P.

**DocumentaÃ§Ã£o Completa**: Ver [CHANGELOG_SUBPOLICIES_DETECTION.md](CHANGELOG_SUBPOLICIES_DETECTION.md)

---

## âš™ï¸ CustomizaÃ§Ã£o

### Ajustar Schema do KG

Editar listas `ALLOWED_NODES` e `ALLOWED_RELATIONSHIPS` na cÃ©lula [6]:

```python
ALLOWED_NODES = [
    "IncidentType",
    "Criterion",
    # ... adicionar novos tipos
]

ALLOWED_RELATIONSHIPS = [
    "DEPENDS_ON",
    "CLASSIFIED_AS",
    # ... adicionar novas relaÃ§Ãµes
]
```

### Ajustar Prompt Guia

Modificar `DECISIONAL_GUIDE` na cÃ©lula [6] para direcionar extraÃ§Ã£o:

```python
DECISIONAL_GUIDE = """
Extraia apenas conceitos para CLASSIFICAR INCIDENTES.

FOQUE EM:
- CritÃ©rios perguntÃ¡veis
- Thresholds numÃ©ricos
- ...
"""
```

### Ajustar Chunking

Modificar funÃ§Ã£o `chunk_por_secoes()` na cÃ©lula [4]:

```python
def chunk_por_secoes(doc: Dict[str, Any], max_chunk_chars: int = 6000):
    # Ajustar max_chunk_chars para chunks maiores/menores
    ...
```

---

## ğŸ› Troubleshooting

### Erro: "Nenhum PDF encontrado"

**Causa**: DiretÃ³rio `padroes_anp/` vazio

**SoluÃ§Ã£o**: Copiar PDFs para `padroes_anp/`

### Erro: "pytesseract nÃ£o disponÃ­vel"

**Causa**: Tesseract OCR nÃ£o instalado

**SoluÃ§Ã£o**:
- Instalar Tesseract (ver seÃ§Ã£o "InstalaÃ§Ã£o do Tesseract")
- OU desabilitar OCR (nÃ£o afeta extraÃ§Ã£o de PDFs com texto)

### Erro: "AZURE_OPENAI_ENDPOINT nÃ£o configurado"

**Causa**: Arquivo `.env` faltando ou incompleto

**SoluÃ§Ã£o**: Criar `.env` com credenciais Azure OpenAI

### Aviso: "Grafo contÃ©m ciclos"

**Causa**: KG gerado possui ciclos (normal em grafos de conhecimento)

**SoluÃ§Ã£o**: O notebook remove ciclos automaticamente na cÃ©lula [7]

### Performance: Notebook muito lento

**Causas possÃ­veis**:
1. Muitos chunks sendo processados
2. Modelo LLM lento
3. Chunks muito grandes

**SoluÃ§Ãµes**:
1. Usar `TEST_MODE = True` para testes iniciais
2. Reduzir `MAX_CHUNKS_TEST`
3. Ajustar `max_chunk_chars` para chunks menores

---

## ğŸ’° Estimativa de Custos (Azure OpenAI)

### Modo de Teste (10 chunks)

- **Tokens estimados**: ~50k tokens
- **Custo estimado**: ~$0.05 USD (com gpt-4o-mini)

### Modo ProduÃ§Ã£o (corpus completo)

Depende do nÃºmero de PDFs e tamanho:

| PDFs | Chunks | Tokens Estimados | Custo (gpt-4o-mini) |
|------|--------|------------------|---------------------|
| 5    | ~100   | ~500k            | ~$0.50 USD          |
| 10   | ~200   | ~1M              | ~$1.00 USD          |
| 20   | ~400   | ~2M              | ~$2.00 USD          |

âš ï¸ **Custos sÃ£o estimativas**. Monitorar uso real no Azure Portal.

---

## ğŸ“ˆ MÃ©tricas de Qualidade

### Boas MÃ©tricas

- **Coverage**: > 80% dos nÃ³s Policy sÃ£o Criterion ou Classification
- **DAG vÃ¡lido**: Policy Graph sem ciclos
- **Profundidade Ã¡rvore**: 3-6 nÃ­veis (nem muito rasa, nem muito profunda)
- **Classes terminais**: > 5 classes diferentes
- **Conectividade KG**: Densidade entre 0.01-0.10

### MÃ©tricas Ruins

- âŒ KG com < 10 nÃ³s (extraÃ§Ã£o falhou)
- âŒ Policy Graph com ciclos nÃ£o resolvidos
- âŒ Ãrvore com profundidade 1 (muito rasa)
- âŒ Todas as folhas com mesma classe (nÃ£o discriminativo)

---

## ğŸ”„ ReexecuÃ§Ã£o e IteraÃ§Ã£o

O notebook Ã© **idempotente** - pode ser reexecutado sem problemas:

1. **Reprocessar PDFs novos**: Adicionar PDFs e reexecutar cÃ©lulas [1]-[3]
2. **Ajustar KG**: Modificar schema/prompt e reexecutar cÃ©lula [6]
3. **Refinar Policy**: Ajustar projeÃ§Ã£o e reexecutar cÃ©lula [7]
4. **Recompilar Ã¡rvore**: Ajustar compilaÃ§Ã£o e reexecutar cÃ©lula [8]

**Artefatos anteriores sÃ£o sobrescritos** - fazer backup se necessÃ¡rio.

---

## ğŸ“š PrÃ³ximos Passos

### ValidaÃ§Ã£o e Refinamento

1. **RevisÃ£o Manual**: Abrir `anp_tree.json` e validar coerÃªncia normativa
2. **Teste com Eventos Reais**: Usar Ã¡rvore no classificador LATS-P
3. **Ajuste de Prompts**: Refinar `DECISIONAL_GUIDE` baseado em resultados
4. **ExpansÃ£o de Schema**: Adicionar novos tipos de nÃ³s/relaÃ§Ãµes se necessÃ¡rio

### IntegraÃ§Ã£o com LATS-P

```python
# Em lats_sistema/lats/tree_loader.py
with open("artifacts/anp_tree.json", "r") as f:
    TREE_DATA = json.load(f)

# Usar TREE_DATA no lugar de Ã¡rvore hardcoded
```

### Melhoria ContÃ­nua

1. **Chunking SemÃ¢ntico**: Usar embeddings para chunks mais inteligentes
2. **ValidaÃ§Ã£o por LLM**: Adicionar etapa de validaÃ§Ã£o automÃ¡tica da Ã¡rvore
3. **Versionamento**: Versionar artefatos (v1, v2, etc)
4. **MÃ©tricas AutomÃ¡ticas**: Adicionar testes de qualidade automÃ¡ticos

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas:

1. Verificar logs de execuÃ§Ã£o no notebook
2. Consultar documentaÃ§Ã£o LangChain: https://python.langchain.com/docs/
3. Revisar documentaÃ§Ã£o NetworkX: https://networkx.org/documentation/

---

**Ãšltima atualizaÃ§Ã£o**: 2025-12-20
**VersÃ£o**: 1.0
