# ANP Classifier - Sistema de ClassificaÃ§Ã£o de Eventos SMS

Sistema inteligente de classificaÃ§Ã£o de eventos de SeguranÃ§a, Meio Ambiente e SaÃºde (SMS) para a Petrobras/ANP, baseado em **LATS-P** (Language Agent Tree Search with Pruning) + **RAG** (Retrieval-Augmented Generation) + **HITL** (Human-in-the-Loop).

---

## ğŸ“‹ Funcionalidades

- **RAG HÃ­brido**: Busca semÃ¢ntica (FAISS) + BM25 + Reranking
- **LATS-P**: NavegaÃ§Ã£o inteligente em Ã¡rvore de decisÃ£o com poda probabilÃ­stica
- **HITL**: IntervenÃ§Ã£o humana quando hÃ¡ incerteza (alta entropia)
- **MemÃ³ria EpisÃ³dica**: ReutilizaÃ§Ã£o de decisÃµes humanas passadas (SQLite + FAISS)
- **Sistema de EvoluÃ§Ã£o Offline**: AnÃ¡lise e melhoria automÃ¡tica da Ã¡rvore de decisÃ£o
- **Interface Web**: Next.js UI + FastAPI Backend

---

## ğŸ› ï¸ InstalaÃ§Ã£o

### 1. PrÃ©-requisitos

- Python 3.10+
- Node.js 18+ (para frontend Next.js)
- Chave API OpenAI

### 2. Clone e Ambiente Virtual

```bash
git clone <repo-url>
cd ANP_classifier

python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# ou
.venv\Scripts\activate  # Windows
```

### 3. Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

### 4. Configurar OpenAI

#### Obter Chave API

1. Acesse: https://platform.openai.com/api-keys
2. Crie uma nova chave API
3. Copie a chave (comeÃ§a com `sk-proj-...`)

#### Configurar VariÃ¡veis de Ambiente

```bash
cp .env.example .env
```

Edite `.env` e adicione sua chave:

```bash
OPENAI_API_KEY=sk-proj-your-actual-key-here
OPENAI_CHAT_MODEL=gpt-4o-mini
OPENAI_EMBED_MODEL=text-embedding-3-small
```

#### Custos Estimados (OpenAI)

| OperaÃ§Ã£o | Custo por evento | Custo 1000 eventos |
|----------|------------------|-------------------|
| ClassificaÃ§Ã£o normal | $0.002 - $0.005 | $2 - $5 |
| FAST_MODE=1 | $0.001 - $0.003 | $1 - $3 |

**Modelos usados:**
- **gpt-4o-mini**: $0.15/1M tokens entrada, $0.60/1M saÃ­da
- **text-embedding-3-small**: $0.02/1M tokens

---

## ğŸš€ Uso

### Backend (FastAPI)

```bash
# Ativar venv
source .venv/bin/activate

# Iniciar servidor
uvicorn backend.main:app --reload

# Servidor rodando em: http://localhost:8000
```

### Frontend (Next.js)

```bash
# Em outro terminal
cd ui-next

# Instalar dependÃªncias (primeira vez)
npm install

# Iniciar dev server
npm run dev

# Interface disponÃ­vel em: http://localhost:3000
```

### API Endpoints

#### POST /predict
Classifica um evento:

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"texto_evento": "Vazamento de Ã³leo na plataforma P-50"}'
```

**Resposta (sem HITL):**
```json
{
  "hitl_required": false,
  "final": {
    "node_id": "1.2.3.1",
    "log_prob": -2.45,
    "historico": [...]
  },
  "state": {...}
}
```

**Resposta (com HITL):**
```json
{
  "hitl_required": true,
  "hitl_metadata": {
    "node_id": "1.2",
    "pergunta": "O evento envolve poluiÃ§Ã£o?",
    "entropia_local": 1.45,
    "children": [
      {"id": "1.2.1", "score": 0.45, "prob": 0.33, ...},
      {"id": "1.2.2", "score": 0.42, "prob": 0.31, ...}
    ]
  },
  "state": {...}
}
```

#### POST /hitl/continue
Continua classificaÃ§Ã£o apÃ³s decisÃ£o humana:

```bash
curl -X POST http://localhost:8000/hitl/continue \
  -H "Content-Type: application/json" \
  -d '{
    "state": {...},
    "selected_child": "1.2.1",
    "justification": "Evento claramente relacionado a poluiÃ§Ã£o marinha"
  }'
```

---

## âš¡ FAST_MODE

Ativa otimizaÃ§Ãµes de performance (contexto RAG reduzido, menos tokens):

```bash
# Em .env
FAST_MODE=1
```

**CaracterÃ­sticas:**
- âœ… ~30% mais rÃ¡pido
- âœ… ~30% mais barato
- âœ… HITL continua funcionando normalmente
- âš ï¸ Pode ter leve reduÃ§Ã£o de precisÃ£o em casos muito complexos

---

## ğŸ§ª Testes

### Teste RÃ¡pido Backend

```bash
# ClassificaÃ§Ã£o simples
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"texto_evento": "Acidente com empilhadeira"}'
```

### Teste Frontend

1. Abra http://localhost:3000
2. Cole: "Vazamento de produto quÃ­mico durante transferÃªncia"
3. Clique "Classificar Evento"
4. Se HITL aparecer: escolha uma opÃ§Ã£o e justifique
5. Veja resultado final

---

## ğŸ“ Estrutura do Projeto

```
ANP_classifier/
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â”œâ”€â”€ main.py           # Rotas API
â”‚   â”œâ”€â”€ models.py         # Schemas Pydantic
â”‚   â””â”€â”€ services/         # LÃ³gica de negÃ³cio
â”œâ”€â”€ lats_sistema/         # Core LATS-P + RAG
â”‚   â”œâ”€â”€ lats/            # Engine LATS-P
â”‚   â”œâ”€â”€ rag/             # Pipeline RAG
â”‚   â”œâ”€â”€ graph/           # Grafo LangGraph
â”‚   â”œâ”€â”€ models/          # LLM/Embeddings factory
â”‚   â””â”€â”€ memory/          # MemÃ³ria episÃ³dica
â”œâ”€â”€ ui-next/             # Frontend Next.js
â”‚   â”œâ”€â”€ app/             # Pages
â”‚   â””â”€â”€ components/      # UI components
â””â”€â”€ data/                # Ãrvore de decisÃ£o + corpus
```

---

## ğŸ”§ Troubleshooting

### Erro: "OPENAI_API_KEY nÃ£o encontrada"

```bash
# Verifique se .env existe
cat .env | grep OPENAI_API_KEY

# Se nÃ£o existir, copie do exemplo
cp .env.example .env
# E edite adicionando sua chave
```

### Erro: "Failed to fetch" no frontend

```bash
# Verifique se backend estÃ¡ rodando
curl http://localhost:8000/docs

# Verifique CORS no backend (jÃ¡ configurado)
```

### HITL nÃ£o aparece

Verifique logs do backend - se a entropia for sempre baixa, o modelo estÃ¡ muito confiante. Eventos ambÃ­guos acionam HITL automaticamente.

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- `HITL_ARCHITECTURE_FINAL.md` - Arquitetura HITL detalhada
- `FAST_MODE_README.md` - Detalhes do modo rÃ¡pido
- `.env.example` - Todas as variÃ¡veis disponÃ­veis

---

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch: `git checkout -b feature/nova-funcionalidade`
3. Commit: `git commit -m 'Adiciona nova funcionalidade'`
4. Push: `git push origin feature/nova-funcionalidade`
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© propriedade da Petrobras/ANP.

---

## ğŸ†˜ Suporte

Para questÃµes ou problemas, abra uma issue no repositÃ³rio.
