# ================================================================
# üß† CRIAR √çNDICE FAISS PARA PADR√ïES / NORMAS PETROBRAS
# ================================================================
import os
import re
from pathlib import Path
from langchain_core.documents import Document
from langchain_community.vectorstores import FAISS

# Carregar vari√°veis de ambiente
from dotenv import load_dotenv
BASE_DIR = Path(__file__).resolve().parent
env_file = BASE_DIR / ".env"
if env_file.exists():
    load_dotenv(env_file)

# ================================================================
# 1. CARREGAR EMBEDDINGS ‚Äî MESMO MODELO DO SISTEMA LATS
# ================================================================
from lats_sistema.models.llm_factory import get_embedding_model

embeddings = get_embedding_model()
print(f"‚úì Usando modelo: {os.getenv('OPENAI_EMBED_MODEL', 'text-embedding-3-small')}")


# ================================================================
# 2. CARREGAR DOCUMENTOS .md DO DIRET√ìRIO
# ================================================================
def carregar_md(dir_path="padroes_petrobras"):
    docs = []

    if not os.path.isdir(dir_path):
        raise Exception(f"Diret√≥rio n√£o encontrado: {dir_path}")

    for filename in os.listdir(dir_path):
        # Ignorar arquivos de checkpoint do Jupyter
        if filename.startswith('.') or '-checkpoint' in filename:
            continue

        if filename.lower().endswith(".md"):
            fpath = os.path.join(dir_path, filename)

            with open(fpath, "r", encoding="utf-8") as f:
                texto = f.read().strip()

            # Sanitiza√ß√£o simples
            texto = texto.replace("```", "")
            texto = re.sub(r"<[^>]+>", "", texto)

            if texto:
                docs.append(Document(page_content=texto, metadata={"source": filename}))

    print(f"‚úì Carregados {len(docs)} documentos .md de {dir_path}")
    return docs


# ================================================================
# 3. QUEBRAR DOCUMENTOS EM CHUNKS (RECOMENDADO PARA RAG)
# ================================================================
def chunk_documentos(docs, chunk_size=900, chunk_overlap=150):
    chunks = []
    for doc in docs:
        texto = doc.page_content
        palavras = texto.split()

        for i in range(0, len(palavras), chunk_size - chunk_overlap):
            trecho = " ".join(palavras[i : i + chunk_size])
            chunks.append(Document(
                page_content=trecho,
                metadata=doc.metadata
            ))

    print(f"Total de chunks gerados: {len(chunks)}")
    return chunks


# ================================================================
# 4. CONSTRUIR √çNDICE FAISS
# ================================================================
def construir_faiss(docs, save_path="data/faiss/index_anp"):
    print("üîÑ Gerando embeddings e criando √≠ndice FAISS...")

    # Criar diret√≥rio se n√£o existir
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    store = FAISS.from_documents(docs, embeddings)
    store.save_local(save_path)
    print(f"‚úÖ √çndice FAISS salvo em: {save_path}")


# ================================================================
# 5. EXECUTAR PIPELINE COMPLETA
# ================================================================
if __name__ == "__main__":
    print("=" * 60)
    print("üß† RECRIANDO √çNDICE FAISS COM OPENAI EMBEDDINGS")
    print("=" * 60)

    docs = carregar_md()
    chunks = chunk_documentos(docs)
    construir_faiss(chunks)

    print("\n‚úÖ CONCLU√çDO! √çndice compat√≠vel com OpenAI criado.")
